{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "import torch\n",
        "from transformers import OwlViTProcessor, OwlViTForObjectDetection\n",
        "\n",
        "# Load processor and model\n",
        "processor = OwlViTProcessor.from_pretrained(\"google/owlvit-base-patch32\")\n",
        "model = OwlViTForObjectDetection.from_pretrained(\"google/owlvit-base-patch32\")\n",
        "\n",
        "# Load image from URL\n",
        "url = \"https://as1.ftcdn.net/v2/jpg/05/02/59/18/1000_F_502591834_Td7o5AUVdIui2Q5YCwaSaPeKTFQMCu9B.jpg\"\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "\n",
        "# Define text queries\n",
        "texts = [[\"Smartwatch\",\"scratch on screen\", \"a crack\", \"broken defects\"]]\n",
        "# Process inputs\n",
        "inputs = processor(text=texts, images=image, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "\n",
        "# Target image sizes (height, width) to rescale box predictions [batch_size, 2]\n",
        "target_sizes = torch.Tensor([image.size[::-1]])\n",
        "\n",
        "# Convert outputs (bounding boxes and class logits) to Pascal VOC format (xmin, ymin, xmax, ymax)\n",
        "results = processor.post_process_object_detection(outputs=outputs, target_sizes=target_sizes, threshold=0.1)\n",
        "\n",
        "# Check for defects\n",
        "i = 0  # Retrieve predictions for the first image for the corresponding text queries\n",
        "text = texts[i]\n",
        "boxes, scores, labels = results[i][\"boxes\"], results[i][\"scores\"], results[i][\"labels\"]\n",
        "\n",
        "defect_found = False\n",
        "for box, score, label in zip(boxes, scores, labels):\n",
        "    if score >= 0.1:\n",
        "        defect_found = True\n",
        "        box = [round(i, 2) for i in box.tolist()]\n",
        "        print(f\"Detected {text[label]} with confidence {round(score.item(), 3)} at location {box}\")\n",
        "\n",
        "if defect_found:\n",
        "    print(\"Defect(s) found in the image.\")\n",
        "else:\n",
        "    print(\"No defect found in the image.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpblHVakY66j",
        "outputId": "feb479ac-bb88-4796-a9b4-79b150d4c6b2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected Smartwatch with confidence 0.164 at location [329.64, 220.11, 639.73, 439.86]\n",
            "Defect(s) found in the image.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9SoW7Xw2gl8Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}